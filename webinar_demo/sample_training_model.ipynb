{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Crop Classification using Eurocrops Data\n",
    "\n",
    "Model architecture adapted from [Garnot et al., 2020](https://openaccess.thecvf.com/content_CVPR_2020/papers/Garnot_Satellite_Image_Time_Series_Classification_With_Pixel-Set_Encoders_and_Temporal_CVPR_2020_paper.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using TinyEuroCrops, only the section below needs to be adjusted for desired variables and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training related parameters \n",
    "# number of epochs of training\n",
    "n_epochs = 10\n",
    "# size of the batches\n",
    "batch_size = 128\n",
    "# focal loss:  focusing parameter\n",
    "gamma = 1\n",
    "# adam: learning rate\n",
    "learning_rate = 1e-5\n",
    "# adam: decay of first order momentum of gradient\n",
    "b1 = 0.9\n",
    "# adam: decay of first order momentum of gradient\n",
    "b2 = 0.999\n",
    "# adam: weight decay (L2 penalty)\n",
    "weight_decay = 1e-6\n",
    "# print frequency of progress meter\n",
    "print_freq = 50\n",
    "\n",
    "\n",
    "# name of checkpoint \n",
    "CP_name= 'checkpoint.pth.tar'\n",
    "# initialize a dummy best accuracy \n",
    "best_acc1 = 0\n",
    "# location to save current tensorboard session\n",
    "current_run = '/Users/ayshahchan/Desktop/PhD/runs/psetae'\n",
    "\n",
    "# Data Directory\n",
    "# this section is specific to TinyEuroCrops, should other data be used please adjust the Data Loader Section for the correct directories as well\n",
    "# root location of data\n",
    "root = '/Users/ayshahchan/Desktop/Education/ESPACE/thesis/codes/data'\n",
    "partition = \"train\"\n",
    "# This notebook uses the train section of Austrian TinyEuroCrops\n",
    "country='AT_T33UWP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader for EuroCrop Demo Data TinyEuroCrops\n",
    "\n",
    "The data loader loads the data from 4 different files: one containing the spectral reflectances for training, one containing the spectral reflectances for testing, one containing the labels for training and the last containing the labels for testing.\n",
    "\n",
    "The code assumes the files are saved under different folders in the same root directory. Should the paths are different, please adjust the code in this section accordingly. This code assumes TinyEuroCrops file structure.\n",
    "\n",
    "\n",
    "Note: although the processing process is similar to the webinar codes, some column names are different. When applying this code on newly processed datasets: please take note the column names crpgrpc and crpgrpn may be hcat_c and hcat_n instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import pandas as pd  \n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import datetime\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8','B9','B10', 'B11', 'B12',\n",
    "       'B8A']\n",
    "classes = [33101011, 33101012, 33101021, 33101022, 33101032, 33101041, 33101042,\n",
    " 33101051, 33101052, 33101060, 33101071, 33101072, 33101080, 33101100,\n",
    " 33102020, 33103000, 33104000, 33105000, 33106020, 33106042, 33106050,\n",
    " 33106060, 33106080, 33106100, 33106120, 33106130, 33107000, 33109000,\n",
    " 33110000, 33111010, 33111022, 33111023, 33112000, 33114000, 33200000,\n",
    " 33301010, 33301030, 33301040, 33304000, 33305000, 33402000, 33500000,\n",
    " 33600000, 33700000,]\n",
    "NORMALIZING_FACTOR = 1e-4\n",
    "PADDING_VALUE = -1\n",
    "\n",
    "class EuroCropsDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root, partition, country ):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "\n",
    "        self.partition = partition\n",
    "        \n",
    "        \n",
    "\n",
    "        self.root = root\n",
    "        if self.partition == \"train\":\n",
    "            self.h5_file_path = os.path.join(self.root, \"HDF5s\", \"train\", country+\"_train\"+\".h5\")\n",
    "        elif  self.partition == \"test\":    \n",
    "            self.h5_file_path = os.path.join(self.root, \"HDF5s\", \"test\", country+\"_test\"+\".h5\")\n",
    "        \n",
    "\n",
    "        \n",
    "        h5_file = h5py.File(self.h5_file_path)\n",
    "        \n",
    "        region_all = []\n",
    "        for name, h5obj in h5_file.items():\n",
    "            if isinstance(h5obj,h5py.Group):\n",
    "                region_all.append(name)\n",
    "        all_labelsfile = []\n",
    "        all_data= []\n",
    "        for i in range(len(region_all)):\n",
    "            region = region_all[i]\n",
    "            csv_file_name = 'demo_eurocrops_' + region + '.csv'\n",
    "            if self.partition == \"train\":\n",
    "                csv_file_path = os.path.join(self.root, \"csv_labels\", \"train\", csv_file_name)\n",
    "        \n",
    "            elif  self.partition == \"test\":    \n",
    "                csv_file_path = os.path.join(self.root, \"csv_labels\", \"test\", csv_file_name)\n",
    "\n",
    "            labelsfile = pd.read_csv(csv_file_path, index_col=0)\n",
    "            all_labelsfile.append(labelsfile)\n",
    "            data = pd.read_hdf(self.h5_file_path, region)\n",
    "            all_data.append(data)\n",
    "\n",
    "        \n",
    "        self.labelsfile = pd.concat(all_labelsfile)\n",
    "        \n",
    "        self.mapping = self.labelsfile.set_index(\"crpgrpc\")\n",
    "        self.classes = self.labelsfile[\"crpgrpc\"].unique()\n",
    "        self.crpgrpn = self.labelsfile.groupby(\"crpgrpc\").first().crpgrpn.values\n",
    "        self.nclasses = len(self.classes)\n",
    "\n",
    "        \n",
    "        self.data = pd.concat(all_data)\n",
    "        \n",
    "        \n",
    "        ids = list(self.data.index)\n",
    "        self.ids = ids    \n",
    "        print('{} parcels in file with {} classes '.format(len(ids),self.nclasses))\n",
    "       \n",
    "        \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "\n",
    "        spectral_data = self.data.loc[self.ids[idx]].sort_index()\n",
    "        \n",
    "        self.id = self.ids[idx]\n",
    "\n",
    "        \n",
    "        crop_no = self.labelsfile.loc[self.id]['crpgrpc']\n",
    "        label = self.labelsfile.loc[self.id]['crpgrpn']\n",
    "        \n",
    "        y_label = classes.index(int(crop_no))\n",
    "\n",
    "        #length = max(map(len,spectral_data))\n",
    "        length = 13\n",
    "        \n",
    "        spectral_data_array = np.empty((0, length))\n",
    "\n",
    "        for ii in range(spectral_data.shape[0]):\n",
    "            if np.isnan(spectral_data[ii]).all()==True:\n",
    "                test = np.zeros(length)\n",
    "                test.shape = (-1, len(test))\n",
    "                spectral_data_array = np.concatenate((spectral_data_array,test))\n",
    "            else:\n",
    "                test = np.array(spectral_data[ii])* NORMALIZING_FACTOR\n",
    "                test.shape = (-1, len(test))\n",
    "                spectral_data_array = np.concatenate((spectral_data_array,test))\n",
    "               \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        X = torch.tensor(spectral_data_array).type(torch.FloatTensor).to(self.device)\n",
    "        # y= torch.from_numpy(np.array(crop_no)).type(torch.LongTensor).to(self.device)\n",
    "        \n",
    "        dates_json = spectral_data.index\n",
    "        max_len = len(spectral_data)\n",
    "        # Instead of taking the position, the numbers of days since the first observation is used\n",
    "        days = torch.zeros(max_len)\n",
    "        date_0 = dates_json[0]\n",
    "        date_0 = datetime.datetime.strptime(str(date_0), \"%Y%m%d\")\n",
    "        days[0] = 0\n",
    "        for i in range(max_len - 1):\n",
    "            date = dates_json[i + 1]\n",
    "            date = datetime.datetime.strptime(str(date), \"%Y%m%d\")\n",
    "            days[i + 1] = (date - date_0).days\n",
    "        days = days.unsqueeze(1)\n",
    "        \n",
    "        return {'data':X, 'label':y_label, 'ids':self.id, 'crop name':label, 'dates':days}\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Model\n",
    "There are three main parts of the model: the multilayer perceptron encoder, the attention layer and the multilayer perceptron decoder. \n",
    "\n",
    "![model diagram](webinar_demo/model.png)\n",
    "![attention diagram](webinar_demo/attention_block.png)\n",
    "\n",
    "\n",
    "You can adjust the model as you wish, whether it is adding more layers or removing the dropout layers. Removing the dropout layers will lead to faster training but may also lead to overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer Perceptrons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP1A(nn.Module):\n",
    "    \"\"\"\n",
    "    Shared Multilayer Perceptron composed of a succession of fully connected layers,\n",
    "    batch-norms and ReLUs\n",
    "    INPUT (N x L x C)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP1A, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 32)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=32)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        x = x.transpose(2, 1)\n",
    "        x = self.bn1(x)     # BN1d takes [batch_size x channels x seq_len] \n",
    "        x = x.transpose(2, 1)\n",
    "        x = self.dropout(x) \n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLP1B(nn.Module):\n",
    "    \"\"\"\n",
    "    Shared Multilayer Perceptron composed of a succession of fully connected layers,\n",
    "    batch-norms and ReLUs\n",
    "    INPUT (N x L x C)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP1B, self).__init__()\n",
    "\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc2(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = self.bn2(x)   # BN1d takes [batch_size x channels x seq_len]\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "    \n",
    "class MLP2A(nn.Module):\n",
    "    \"\"\"\n",
    "    Multilayer Perceptron number three\n",
    "    INPUT (N x L)\n",
    "    Lazylinear is used as the number of infeatures changes with different sequence lengths\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP2A, self).__init__()\n",
    "        self.fc1 = nn.LazyLinear(64)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=64)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "class MLP2B(nn.Module):\n",
    "    \"\"\"\n",
    "    Multilayer Perceptron number three\n",
    "    INPUT (N x L)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP2B, self).__init__()\n",
    "\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLP3A(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder Multilayer Perceptron.\n",
    "    INPUT (N x L)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP3A, self).__init__()\n",
    "  \n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=32)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    " \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MLP3B(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder Multilayer Perceptron.\n",
    "    INPUT (N x L)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP3B, self).__init__()\n",
    "\n",
    "        self.fc3 = nn.Linear(32, 44)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral Encoder\n",
    "\n",
    "A simple encoder for initial feature extraction mainly in the spectral domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class SpectralEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    First part of the presented architecture.\n",
    "    Yields to a spatio-spectral embedding at time t\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device):\n",
    "        super(SpectralEncoder, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.mlp1a = MLP1A()\n",
    "        self.mlp1b = MLP1B()\n",
    "        \n",
    "\n",
    "    def forward(self, x):  # x: [batch_size x  seq_len x channels:10]\n",
    "\n",
    "        \n",
    "        batch_size, seq_len, channels = x.shape\n",
    "        \n",
    "\n",
    "        mlp1_output = self.mlp1a(x)                              # [batch_size x seq_len x hidden_state:32]\n",
    "        mlp1_output = self.mlp1b(mlp1_output)                   # [batch_size x seq_len x hidden_state:64]\n",
    "\n",
    "\n",
    "        pooled = mlp1_output.contiguous().view(batch_size, seq_len, -1)  # [batch_size x seq_len x hidden_state:64]\n",
    "        pooled = pooled.type('torch.FloatTensor')\n",
    "\n",
    "        return pooled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Layer\n",
    "\n",
    "For Positional Encoding: one of the inputs is days. This refers to the number of days since first data point due to the irregular frequency of data acquisition. This should be a readily availble output of the data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self,days, d_e=64, max_len=80):\n",
    "        super(PositionalEncoding, self).__init__()        \n",
    "\n",
    "        # Calculate the positional encoding p\n",
    "        p = torch.zeros(max_len, d_e)\n",
    "        \n",
    "        div_term = torch.exp(torch.arange(0, d_e, 2).float() * (-math.log(1000.0) / d_e))\n",
    "        p[:, 0::2] = torch.sin(days * div_term)\n",
    "        p[:, 1::2] = torch.cos(days * div_term)\n",
    "        p = p.unsqueeze(0)\n",
    "        \n",
    "        self.register_buffer('p', p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x + self.p\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, d_k, h):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.h = h\n",
    "        self.d_k = d_k\n",
    "        self.d_e = self.d_k * self.h\n",
    "\n",
    "        self.fc1_q = nn.Linear(self.d_e, self.d_e)\n",
    "        self.fc1_k = nn.Linear(self.d_e, self.d_e)\n",
    "        self.fc1_v = nn.Linear(self.d_e, self.d_e)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.d_k*self.h, self.d_e)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.layer_norm = nn.LayerNorm(self.d_k*self.h)\n",
    "\n",
    "\n",
    "        self.q = ()\n",
    "        self.k = ()\n",
    "        self.v = ()\n",
    "        self.attention_scores = ()\n",
    "        self.attention_output = ()\n",
    "        self.attention_probs = ()\n",
    "\n",
    "\n",
    "    def forward(self, e_p, batch_size, seq_len):\n",
    "        q = self.fc1_q(e_p)         # [batch_size x seq_len x hidden_state:64]\n",
    "        q = q.view(batch_size,  seq_len, self.h, self.d_k)     # [batch_size x seq_len x num_heads x d_k]\n",
    "        q = q.permute(0, 2, 1, 3).contiguous().view(-1,seq_len,  self.d_k)     # [batch_size * num_heads x seq_len x d_k]\n",
    "        self.q = q\n",
    "        # Keys\n",
    "        k = self.fc1_k(e_p)                                                 # [batch_size x seq_len x hidden_state:64]\n",
    "        k = k.view(batch_size, seq_len, self.h, self.d_k)                   # [batch_size x seq_len x num_heads x d_k]\n",
    "        k = k.permute(0, 2, 1, 3).contiguous().view(-1, seq_len, self.d_k)  # [batch_size * num_heads x seq_len x d_k]\n",
    "        self.k = k\n",
    "        # Values \n",
    "          \n",
    "        v = self.fc1_v(e_p)  # [batch_size * num_heads x seq_len x hidden:64]\n",
    "        v = v.view(batch_size, seq_len, self.h, self.d_k)       # [batch_size x seq_len x num_heads x d_k]\n",
    "        v = v.permute(0, 2, 1, 3).contiguous().view(-1, seq_len, self.d_k) # [batch_size * num_heads x seq_len x d_k]\n",
    "        self.v = v\n",
    "        \n",
    "        # Attention\n",
    "        attention_scores = q.matmul(k.transpose(-2, -1)) / math.sqrt(self.d_k)      # [batch_size * num_heads x seq_len x seq_len]\n",
    "        self.attention_scores = attention_scores        # ,4,80,80  batch_size * num_heads x seq_len x seq_len\n",
    "        \n",
    "        attention_probs = F.softmax(attention_scores, dim=-1)               # [batch_size * num_heads x 64 (d_e) x seq_len]\n",
    "       \n",
    "        attention_output = torch.matmul(attention_probs, v).squeeze()       #  [batch_size* 4 (num_h) x 80 (seq length) x 64 (d_e)]\n",
    "        \n",
    "        \n",
    "        attention_output = attention_output.view(self.h, batch_size,seq_len, self.d_k)  # num_heads x batch_size x seq_len x dk 16\n",
    "        attention_output = attention_output.permute(1,2,0,3).contiguous().view(batch_size,seq_len,-1) # batch_size x seq_len x dk * num_heads (d_e 64)\n",
    "\n",
    "\n",
    "        ################ adding drop out and layer norm to reduce overfitting\n",
    "        attention_output = self.dropout(self.fc1(attention_output)) # batch_size x seq_len x dk * num_heads (d_e 64)\n",
    "        attention_output = self.layer_norm(attention_output+e_p) # batch_size x seq_len x dk * num_heads (d_e 64)\n",
    "        \n",
    "        self.attention_output = attention_output\n",
    "        self.attention_probs = attention_probs\n",
    "\n",
    "        return attention_output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal Attention Encoder\n",
    "\n",
    "Encoder that primarily extracts features in the temporal domain by leveraging the attention mechanism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAE(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(TAE, self).__init__()\n",
    "        self.mlp2a = MLP2A()\n",
    "        self.mlp2b = MLP2B()\n",
    "        self.mlp3a = MLP3A()\n",
    "        self.decoder = MLP3B()\n",
    "\n",
    "\n",
    "    def forward(self, attention_output):    \n",
    "        \n",
    "        o_hat = self.mlp2a(attention_output)\n",
    "        o_hat = self.mlp2b(o_hat)\n",
    "        o_hat = self.mlp3a(o_hat)\n",
    "\n",
    "        \n",
    "        output = self.decoder(o_hat)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the individual modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class PSE_TAE(nn.Module):\n",
    "\n",
    "    def __init__(self, device, heads=4, d_e= 64):\n",
    "        super(PSE_TAE, self).__init__()\n",
    "        self.spectral_encoder = SpectralEncoder(device)\n",
    "        \n",
    "  \n",
    "            \n",
    "        self.d_e = d_e\n",
    "        self.d_k = d_e // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.attn = AttentionLayer(self.d_k,self.h)\n",
    "        self.tae = TAE()\n",
    "\n",
    "\n",
    "             \n",
    "        self.R0 = ()\n",
    "\n",
    "    def forward(self, x, days):\n",
    "        encoding = self.spectral_encoder(x)\n",
    "        \n",
    "\n",
    "        batch_size, seq_len, hidden_state = encoding.size()\n",
    "\n",
    "        pos_encoding = PositionalEncoding(days[0,:,:].squeeze(0), d_e = self.d_e, max_len=seq_len)\n",
    "\n",
    "        e_p = pos_encoding(encoding)\n",
    "        # Queries\n",
    "        attention_output1 = self.attn(e_p, batch_size,seq_len)\n",
    "        attention_output = attention_output1.contiguous().view(batch_size, -1) # batch_size x seq_len * dk * num_heads (d_e 64)\n",
    "        # Output\n",
    "        batch_size, seq_len = attention_output.size()\n",
    "        output = self.tae(attention_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    From https://github.com/clcarwin/focal_loss_pytorch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha, (float, int)): self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
    "        if isinstance(alpha, list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim() > 2:\n",
    "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1, 2)  # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1, input.size(2))  # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        logpt = logpt.gather(1, target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0, target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(current_run)\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader,\n",
    "          pse_tae,\n",
    "          focal_loss,\n",
    "          optimizer,\n",
    "          epoch,\n",
    "          print_freq,\n",
    "          device):\n",
    "\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    # pse_time = AverageMeter('PSE', ':6.3f')\n",
    "    # tae_time = AverageMeter('TAE', ':6.3f')\n",
    "    # decode_time = AverageMeter('Decode', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@2', ':6.2f')\n",
    "    progress = ProgressMeter(len(train_loader),\n",
    "                             [batch_time, data_time, losses, top1, top5],\n",
    "                             prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # -------------------------\n",
    "    #  Put Models in Train Mode\n",
    "    # -------------------------\n",
    "    pse_tae.train()\n",
    "\n",
    "    end = time.time()\n",
    "    # running_loss = 0.0\n",
    "    # running_correct = 0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Get training data\n",
    "        data = batch['data'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        days = batch[\"dates\"].to(device)\n",
    "        \n",
    "        \n",
    "        # ---------------------------------\n",
    "        #  Train Everything together\n",
    "        # ---------------------------------\n",
    "        optimizer.zero_grad()\n",
    "        output = pse_tae(data,days)\n",
    "        _, prediction = torch.max(output.data, 1)\n",
    "\n",
    "        # ---------------------------------\n",
    "        #  Loss\n",
    "        # ---------------------------------\n",
    "\n",
    "        # Focal Loss between output and target\n",
    "        loss = focal_loss(output.to(device), label)\n",
    "\n",
    "        # ---------------------------------\n",
    "        #  Record Stats\n",
    "        # ---------------------------------\n",
    "        # Measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, label, topk=(1, 2))\n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        top1.update(acc1[0], data.size(0))\n",
    "        top5.update(acc5[0], data.size(0))\n",
    "\n",
    "        # ---------------------------------\n",
    "        #  Gradient & SGD step\n",
    "        # ---------------------------------\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ---------------------------------\n",
    "        #  Time\n",
    "        # ---------------------------------\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)\n",
    "            # for tensorboard\n",
    "            writer.add_scalar('train loss', loss.item(), epoch * len(train_loader) + i)\n",
    "            \n",
    "            writer.add_scalar('accuracy best', acc1, epoch * len(train_loader) + i)\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def validate(val_loader, pse_tae, focal_loss, epoch, print_freq, device):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(len(val_loader), [batch_time, losses, top1, top5], prefix='Test: ')\n",
    "\n",
    "    # -------------------------\n",
    "    #  Put Models in Eval Mode\n",
    "    # -------------------------\n",
    "    pse_tae.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, val_batch in enumerate(val_loader):\n",
    "            # Get validation data\n",
    "            data_val = val_batch['data'].to(device)\n",
    "            label_val = val_batch['label'].to(device)\n",
    "            days_val = val_batch[\"dates\"].to(device)\n",
    "     \n",
    "\n",
    "            # -------------------------\n",
    "            #  Compute Predictions\n",
    "            # -------------------------\n",
    "            output = pse_tae(data_val, days_val)\n",
    "            loss = focal_loss(output.to(device), label_val)\n",
    "            _, prediction = torch.max(output.data, 1)\n",
    "\n",
    "            # ---------------------------------\n",
    "            #  Record Stats\n",
    "            # ---------------------------------\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, label_val, topk=(1, 5))\n",
    "            losses.update(loss.item(), data_val.size(0))\n",
    "            top1.update(acc1[0], data_val.size(0))\n",
    "            top5.update(acc5[0], data_val.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                progress.display(i)\n",
    "                writer.add_scalar('val loss', loss.item(), epoch * len(val_loader) + i)\n",
    "            #writer.add_scalar('accuracy', running_correct/100, epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('val accuracy', acc1, epoch * len(val_loader) + i)\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg, losses.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename=CP_name):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'best_'+filename)\n",
    "\n",
    "def load_checkpoint(model, optimizer,  filename=CP_name):\n",
    "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        \n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model, optimizer, start_epoch\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=10, min_delta=0.2):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345970 parcels in file with 44 classes \n",
      "=> no checkpoint found at 'checkpoint.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/2163]\tTime  1.982 ( 1.982)\tData  1.762 ( 1.762)\tLoss 3.7913e+00 (3.7913e+00)\tAcc@1   2.34 (  2.34)\tAcc@2   3.91 (  3.91)\n",
      "Epoch: [0][  50/2163]\tTime  0.239 ( 0.281)\tData  0.183 ( 0.218)\tLoss 3.7034e+00 (3.8050e+00)\tAcc@1   7.03 (  3.74)\tAcc@2  10.94 (  6.43)\n",
      "Epoch: [0][ 100/2163]\tTime  0.242 ( 0.263)\tData  0.184 ( 0.202)\tLoss 3.7096e+00 (3.7637e+00)\tAcc@1   5.47 (  4.56)\tAcc@2   9.38 (  7.80)\n",
      "Epoch: [0][ 150/2163]\tTime  0.241 ( 0.257)\tData  0.184 ( 0.197)\tLoss 3.6428e+00 (3.7221e+00)\tAcc@1   5.47 (  5.74)\tAcc@2  11.72 (  9.41)\n",
      "Epoch: [0][ 200/2163]\tTime  0.240 ( 0.254)\tData  0.184 ( 0.194)\tLoss 3.5550e+00 (3.6899e+00)\tAcc@1   7.81 (  6.72)\tAcc@2  12.50 ( 10.73)\n",
      "Epoch: [0][ 250/2163]\tTime  0.242 ( 0.252)\tData  0.185 ( 0.192)\tLoss 3.5681e+00 (3.6571e+00)\tAcc@1  10.16 (  7.88)\tAcc@2  16.41 ( 12.34)\n",
      "Epoch: [0][ 300/2163]\tTime  0.240 ( 0.251)\tData  0.184 ( 0.192)\tLoss 3.4271e+00 (3.6268e+00)\tAcc@1  19.53 (  9.09)\tAcc@2  24.22 ( 13.87)\n",
      "Epoch: [0][ 350/2163]\tTime  0.257 ( 0.250)\tData  0.200 ( 0.191)\tLoss 3.4175e+00 (3.6011e+00)\tAcc@1  16.41 ( 10.02)\tAcc@2  25.00 ( 15.05)\n",
      "Epoch: [0][ 400/2163]\tTime  0.247 ( 0.250)\tData  0.190 ( 0.190)\tLoss 3.3694e+00 (3.5757e+00)\tAcc@1  21.88 ( 10.94)\tAcc@2  28.12 ( 16.24)\n",
      "Epoch: [0][ 450/2163]\tTime  0.242 ( 0.249)\tData  0.184 ( 0.190)\tLoss 3.2605e+00 (3.5511e+00)\tAcc@1  24.22 ( 11.94)\tAcc@2  33.59 ( 17.47)\n",
      "Epoch: [0][ 500/2163]\tTime  0.240 ( 0.249)\tData  0.183 ( 0.189)\tLoss 3.2606e+00 (3.5279e+00)\tAcc@1  25.00 ( 12.77)\tAcc@2  30.47 ( 18.63)\n",
      "Epoch: [0][ 550/2163]\tTime  0.239 ( 0.248)\tData  0.183 ( 0.189)\tLoss 3.1921e+00 (3.5053e+00)\tAcc@1  28.12 ( 13.62)\tAcc@2  38.28 ( 19.82)\n",
      "Epoch: [0][ 600/2163]\tTime  0.242 ( 0.248)\tData  0.183 ( 0.189)\tLoss 3.2585e+00 (3.4835e+00)\tAcc@1  21.09 ( 14.36)\tAcc@2  32.03 ( 20.98)\n",
      "Epoch: [0][ 650/2163]\tTime  0.243 ( 0.248)\tData  0.183 ( 0.189)\tLoss 3.1621e+00 (3.4629e+00)\tAcc@1  27.34 ( 15.16)\tAcc@2  42.19 ( 22.13)\n",
      "Epoch: [0][ 700/2163]\tTime  0.248 ( 0.248)\tData  0.184 ( 0.188)\tLoss 3.1489e+00 (3.4436e+00)\tAcc@1  28.12 ( 15.89)\tAcc@2  35.16 ( 23.18)\n",
      "Epoch: [0][ 750/2163]\tTime  0.241 ( 0.247)\tData  0.183 ( 0.188)\tLoss 3.1000e+00 (3.4245e+00)\tAcc@1  32.81 ( 16.68)\tAcc@2  42.97 ( 24.28)\n",
      "Epoch: [0][ 800/2163]\tTime  0.242 ( 0.247)\tData  0.184 ( 0.188)\tLoss 3.1956e+00 (3.4058e+00)\tAcc@1  26.56 ( 17.46)\tAcc@2  36.72 ( 25.35)\n",
      "Epoch: [0][ 850/2163]\tTime  0.242 ( 0.247)\tData  0.184 ( 0.188)\tLoss 2.9933e+00 (3.3881e+00)\tAcc@1  35.94 ( 18.20)\tAcc@2  50.78 ( 26.35)\n",
      "Epoch: [0][ 900/2163]\tTime  0.242 ( 0.247)\tData  0.183 ( 0.188)\tLoss 3.1286e+00 (3.3711e+00)\tAcc@1  31.25 ( 18.90)\tAcc@2  47.66 ( 27.31)\n",
      "Epoch: [0][ 950/2163]\tTime  0.238 ( 0.247)\tData  0.180 ( 0.188)\tLoss 2.9647e+00 (3.3546e+00)\tAcc@1  35.16 ( 19.59)\tAcc@2  47.66 ( 28.30)\n",
      "Epoch: [0][1000/2163]\tTime  0.246 ( 0.247)\tData  0.188 ( 0.188)\tLoss 3.0554e+00 (3.3389e+00)\tAcc@1  39.84 ( 20.31)\tAcc@2  46.09 ( 29.25)\n",
      "Epoch: [0][1050/2163]\tTime  0.247 ( 0.246)\tData  0.188 ( 0.187)\tLoss 3.0616e+00 (3.3230e+00)\tAcc@1  31.25 ( 21.03)\tAcc@2  41.41 ( 30.20)\n",
      "Epoch: [0][1100/2163]\tTime  0.243 ( 0.246)\tData  0.185 ( 0.187)\tLoss 3.0372e+00 (3.3078e+00)\tAcc@1  31.25 ( 21.75)\tAcc@2  49.22 ( 31.09)\n",
      "Epoch: [0][1150/2163]\tTime  0.240 ( 0.246)\tData  0.182 ( 0.187)\tLoss 2.9578e+00 (3.2926e+00)\tAcc@1  37.50 ( 22.46)\tAcc@2  52.34 ( 31.97)\n",
      "Epoch: [0][1200/2163]\tTime  0.238 ( 0.246)\tData  0.180 ( 0.187)\tLoss 2.9817e+00 (3.2777e+00)\tAcc@1  33.59 ( 23.12)\tAcc@2  46.88 ( 32.85)\n",
      "Epoch: [0][1250/2163]\tTime  0.239 ( 0.245)\tData  0.184 ( 0.187)\tLoss 2.9220e+00 (3.2637e+00)\tAcc@1  37.50 ( 23.77)\tAcc@2  53.12 ( 33.67)\n",
      "Epoch: [0][1300/2163]\tTime  0.240 ( 0.245)\tData  0.186 ( 0.187)\tLoss 2.9404e+00 (3.2496e+00)\tAcc@1  40.62 ( 24.43)\tAcc@2  52.34 ( 34.50)\n",
      "Epoch: [0][1350/2163]\tTime  0.235 ( 0.245)\tData  0.181 ( 0.186)\tLoss 2.8527e+00 (3.2362e+00)\tAcc@1  42.97 ( 25.03)\tAcc@2  57.81 ( 35.28)\n",
      "Epoch: [0][1400/2163]\tTime  0.243 ( 0.245)\tData  0.187 ( 0.186)\tLoss 2.9144e+00 (3.2229e+00)\tAcc@1  39.06 ( 25.68)\tAcc@2  55.47 ( 36.05)\n",
      "Epoch: [0][1450/2163]\tTime  0.239 ( 0.245)\tData  0.181 ( 0.186)\tLoss 2.9401e+00 (3.2101e+00)\tAcc@1  38.28 ( 26.27)\tAcc@2  51.56 ( 36.79)\n",
      "Epoch: [0][1500/2163]\tTime  0.235 ( 0.245)\tData  0.180 ( 0.186)\tLoss 2.8638e+00 (3.1969e+00)\tAcc@1  40.62 ( 26.89)\tAcc@2  54.69 ( 37.54)\n",
      "Epoch: [0][1550/2163]\tTime  0.237 ( 0.245)\tData  0.180 ( 0.186)\tLoss 2.8429e+00 (3.1845e+00)\tAcc@1  43.75 ( 27.47)\tAcc@2  57.03 ( 38.23)\n",
      "Epoch: [0][1600/2163]\tTime  0.249 ( 0.244)\tData  0.193 ( 0.186)\tLoss 2.7999e+00 (3.1724e+00)\tAcc@1  41.41 ( 28.04)\tAcc@2  64.06 ( 38.92)\n",
      "Epoch: [0][1650/2163]\tTime  0.240 ( 0.244)\tData  0.185 ( 0.186)\tLoss 2.7710e+00 (3.1603e+00)\tAcc@1  42.19 ( 28.57)\tAcc@2  56.25 ( 39.58)\n",
      "Epoch: [0][1700/2163]\tTime  0.248 ( 0.245)\tData  0.191 ( 0.186)\tLoss 2.6889e+00 (3.1487e+00)\tAcc@1  49.22 ( 29.10)\tAcc@2  61.72 ( 40.21)\n",
      "Epoch: [0][1750/2163]\tTime  0.244 ( 0.245)\tData  0.188 ( 0.186)\tLoss 2.7609e+00 (3.1367e+00)\tAcc@1  46.09 ( 29.66)\tAcc@2  61.72 ( 40.84)\n",
      "Epoch: [0][1800/2163]\tTime  0.241 ( 0.245)\tData  0.184 ( 0.186)\tLoss 2.7291e+00 (3.1249e+00)\tAcc@1  44.53 ( 30.20)\tAcc@2  63.28 ( 41.48)\n",
      "Epoch: [0][1850/2163]\tTime  0.241 ( 0.245)\tData  0.186 ( 0.186)\tLoss 2.7054e+00 (3.1131e+00)\tAcc@1  52.34 ( 30.73)\tAcc@2  64.84 ( 42.11)\n",
      "Epoch: [0][1900/2163]\tTime  0.242 ( 0.245)\tData  0.185 ( 0.186)\tLoss 2.7105e+00 (3.1017e+00)\tAcc@1  46.88 ( 31.22)\tAcc@2  58.59 ( 42.69)\n",
      "Epoch: [0][1950/2163]\tTime  0.241 ( 0.245)\tData  0.184 ( 0.186)\tLoss 2.6557e+00 (3.0909e+00)\tAcc@1  51.56 ( 31.71)\tAcc@2  69.53 ( 43.25)\n",
      "Epoch: [0][2000/2163]\tTime  0.241 ( 0.245)\tData  0.184 ( 0.186)\tLoss 2.7041e+00 (3.0799e+00)\tAcc@1  42.19 ( 32.20)\tAcc@2  55.47 ( 43.79)\n",
      "Epoch: [0][2050/2163]\tTime  0.242 ( 0.245)\tData  0.183 ( 0.186)\tLoss 2.6421e+00 (3.0688e+00)\tAcc@1  53.12 ( 32.70)\tAcc@2  70.31 ( 44.34)\n",
      "Epoch: [0][2100/2163]\tTime  0.244 ( 0.244)\tData  0.186 ( 0.186)\tLoss 2.7358e+00 (3.0580e+00)\tAcc@1  42.19 ( 33.17)\tAcc@2  56.25 ( 44.87)\n",
      "Epoch: [0][2150/2163]\tTime  0.247 ( 0.244)\tData  0.187 ( 0.186)\tLoss 2.5859e+00 (3.0473e+00)\tAcc@1  55.47 ( 33.64)\tAcc@2  66.41 ( 45.39)\n",
      "Test: [  0/541]\tTime  0.210 ( 0.210)\tLoss 2.3178e+00 (2.3178e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  85.16 ( 85.16)\n",
      "Test: [ 50/541]\tTime  0.247 ( 0.224)\tLoss 2.4690e+00 (2.4189e+00)\tAcc@1  53.91 ( 57.87)\tAcc@5  81.25 ( 81.72)\n",
      "Test: [100/541]\tTime  0.214 ( 0.223)\tLoss 2.4253e+00 (2.4163e+00)\tAcc@1  57.03 ( 58.26)\tAcc@5  84.38 ( 82.01)\n",
      "Test: [150/541]\tTime  0.223 ( 0.227)\tLoss 2.3198e+00 (2.4143e+00)\tAcc@1  64.06 ( 58.59)\tAcc@5  84.38 ( 82.02)\n",
      "Test: [200/541]\tTime  0.211 ( 0.225)\tLoss 2.3086e+00 (2.4110e+00)\tAcc@1  63.28 ( 58.80)\tAcc@5  80.47 ( 82.00)\n",
      "Test: [250/541]\tTime  0.215 ( 0.224)\tLoss 2.3970e+00 (2.4135e+00)\tAcc@1  60.16 ( 58.65)\tAcc@5  80.47 ( 81.97)\n",
      "Test: [300/541]\tTime  0.216 ( 0.224)\tLoss 2.4776e+00 (2.4165e+00)\tAcc@1  57.81 ( 58.56)\tAcc@5  78.91 ( 81.93)\n",
      "Test: [350/541]\tTime  0.214 ( 0.224)\tLoss 2.2886e+00 (2.4163e+00)\tAcc@1  66.41 ( 58.54)\tAcc@5  84.38 ( 81.95)\n",
      "Test: [400/541]\tTime  0.210 ( 0.223)\tLoss 2.3252e+00 (2.4137e+00)\tAcc@1  61.72 ( 58.62)\tAcc@5  87.50 ( 82.09)\n",
      "Test: [450/541]\tTime  0.228 ( 0.223)\tLoss 2.3942e+00 (2.4142e+00)\tAcc@1  59.38 ( 58.51)\tAcc@5  83.59 ( 82.07)\n",
      "Test: [500/541]\tTime  0.220 ( 0.222)\tLoss 2.4589e+00 (2.4141e+00)\tAcc@1  57.03 ( 58.51)\tAcc@5  82.03 ( 82.10)\n",
      " * Acc@1 58.505 Acc@5 82.062\n",
      "Epoch: [1][   0/2163]\tTime  0.281 ( 0.281)\tData  0.219 ( 0.219)\tLoss 2.5936e+00 (2.5936e+00)\tAcc@1  55.47 ( 55.47)\tAcc@2  65.62 ( 65.62)\n",
      "Epoch: [1][  50/2163]\tTime  0.246 ( 0.255)\tData  0.188 ( 0.194)\tLoss 2.6727e+00 (2.5910e+00)\tAcc@1  53.91 ( 53.32)\tAcc@2  64.84 ( 67.14)\n",
      "Epoch: [1][ 100/2163]\tTime  0.248 ( 0.254)\tData  0.191 ( 0.193)\tLoss 2.5670e+00 (2.5772e+00)\tAcc@1  63.28 ( 53.69)\tAcc@2  71.09 ( 67.50)\n",
      "Epoch: [1][ 150/2163]\tTime  0.248 ( 0.256)\tData  0.190 ( 0.195)\tLoss 2.5906e+00 (2.5676e+00)\tAcc@1  57.03 ( 53.79)\tAcc@2  67.97 ( 68.02)\n",
      "Epoch: [1][ 200/2163]\tTime  0.249 ( 0.255)\tData  0.191 ( 0.194)\tLoss 2.4999e+00 (2.5572e+00)\tAcc@1  55.47 ( 54.16)\tAcc@2  66.41 ( 68.35)\n",
      "Epoch: [1][ 250/2163]\tTime  0.249 ( 0.255)\tData  0.192 ( 0.194)\tLoss 2.4597e+00 (2.5487e+00)\tAcc@1  61.72 ( 54.33)\tAcc@2  76.56 ( 68.56)\n",
      "Epoch: [1][ 300/2163]\tTime  0.249 ( 0.254)\tData  0.191 ( 0.193)\tLoss 2.5284e+00 (2.5392e+00)\tAcc@1  50.00 ( 54.50)\tAcc@2  67.97 ( 68.85)\n",
      "Epoch: [1][ 350/2163]\tTime  0.256 ( 0.255)\tData  0.191 ( 0.194)\tLoss 2.4046e+00 (2.5323e+00)\tAcc@1  65.62 ( 54.66)\tAcc@2  76.56 ( 68.95)\n",
      "Epoch: [1][ 400/2163]\tTime  0.260 ( 0.255)\tData  0.203 ( 0.194)\tLoss 2.4645e+00 (2.5274e+00)\tAcc@1  57.03 ( 54.83)\tAcc@2  71.09 ( 69.10)\n",
      "Epoch: [1][ 450/2163]\tTime  0.248 ( 0.255)\tData  0.188 ( 0.194)\tLoss 2.4966e+00 (2.5189e+00)\tAcc@1  53.12 ( 55.11)\tAcc@2  64.06 ( 69.36)\n",
      "Epoch: [1][ 500/2163]\tTime  0.244 ( 0.254)\tData  0.188 ( 0.193)\tLoss 2.4227e+00 (2.5111e+00)\tAcc@1  57.81 ( 55.40)\tAcc@2  73.44 ( 69.59)\n",
      "Epoch: [1][ 550/2163]\tTime  0.247 ( 0.254)\tData  0.186 ( 0.193)\tLoss 2.4741e+00 (2.5042e+00)\tAcc@1  50.00 ( 55.58)\tAcc@2  71.88 ( 69.72)\n",
      "Epoch: [1][ 600/2163]\tTime  0.255 ( 0.254)\tData  0.191 ( 0.193)\tLoss 2.4243e+00 (2.4964e+00)\tAcc@1  56.25 ( 55.80)\tAcc@2  71.09 ( 69.94)\n",
      "Epoch: [1][ 650/2163]\tTime  0.244 ( 0.253)\tData  0.187 ( 0.193)\tLoss 2.4391e+00 (2.4905e+00)\tAcc@1  63.28 ( 55.86)\tAcc@2  73.44 ( 69.98)\n",
      "Epoch: [1][ 700/2163]\tTime  0.251 ( 0.253)\tData  0.185 ( 0.192)\tLoss 2.3754e+00 (2.4841e+00)\tAcc@1  59.38 ( 55.97)\tAcc@2  71.88 ( 70.10)\n",
      "Epoch: [1][ 750/2163]\tTime  0.247 ( 0.253)\tData  0.187 ( 0.192)\tLoss 2.4337e+00 (2.4768e+00)\tAcc@1  54.69 ( 56.14)\tAcc@2  73.44 ( 70.29)\n",
      "Epoch: [1][ 800/2163]\tTime  0.252 ( 0.253)\tData  0.192 ( 0.192)\tLoss 2.3962e+00 (2.4700e+00)\tAcc@1  55.47 ( 56.26)\tAcc@2  71.09 ( 70.43)\n",
      "Epoch: [1][ 850/2163]\tTime  0.266 ( 0.253)\tData  0.206 ( 0.192)\tLoss 2.3871e+00 (2.4623e+00)\tAcc@1  57.81 ( 56.43)\tAcc@2  72.66 ( 70.58)\n",
      "Epoch: [1][ 900/2163]\tTime  0.253 ( 0.253)\tData  0.189 ( 0.192)\tLoss 2.4157e+00 (2.4557e+00)\tAcc@1  53.12 ( 56.58)\tAcc@2  75.78 ( 70.73)\n",
      "Epoch: [1][ 950/2163]\tTime  0.249 ( 0.253)\tData  0.189 ( 0.192)\tLoss 2.3957e+00 (2.4479e+00)\tAcc@1  57.03 ( 56.77)\tAcc@2  71.88 ( 70.90)\n",
      "Epoch: [1][1000/2163]\tTime  0.245 ( 0.253)\tData  0.185 ( 0.192)\tLoss 2.2428e+00 (2.4403e+00)\tAcc@1  64.06 ( 56.92)\tAcc@2  77.34 ( 71.08)\n",
      "Epoch: [1][1050/2163]\tTime  0.253 ( 0.253)\tData  0.192 ( 0.192)\tLoss 2.3820e+00 (2.4337e+00)\tAcc@1  54.69 ( 57.05)\tAcc@2  74.22 ( 71.24)\n",
      "Epoch: [1][1100/2163]\tTime  0.247 ( 0.253)\tData  0.189 ( 0.192)\tLoss 2.3161e+00 (2.4270e+00)\tAcc@1  62.50 ( 57.19)\tAcc@2  75.00 ( 71.36)\n",
      "Epoch: [1][1150/2163]\tTime  0.255 ( 0.253)\tData  0.192 ( 0.192)\tLoss 2.2453e+00 (2.4204e+00)\tAcc@1  63.28 ( 57.33)\tAcc@2  76.56 ( 71.48)\n",
      "Epoch: [1][1200/2163]\tTime  0.252 ( 0.253)\tData  0.189 ( 0.192)\tLoss 2.3421e+00 (2.4140e+00)\tAcc@1  50.78 ( 57.42)\tAcc@2  67.97 ( 71.58)\n",
      "Epoch: [1][1250/2163]\tTime  0.260 ( 0.254)\tData  0.199 ( 0.192)\tLoss 2.1783e+00 (2.4074e+00)\tAcc@1  62.50 ( 57.54)\tAcc@2  74.22 ( 71.69)\n",
      "Epoch: [1][1300/2163]\tTime  0.254 ( 0.254)\tData  0.194 ( 0.192)\tLoss 2.1098e+00 (2.4008e+00)\tAcc@1  65.62 ( 57.66)\tAcc@2  78.12 ( 71.79)\n",
      "Epoch: [1][1350/2163]\tTime  0.253 ( 0.254)\tData  0.194 ( 0.193)\tLoss 2.3276e+00 (2.3943e+00)\tAcc@1  55.47 ( 57.77)\tAcc@2  71.88 ( 71.91)\n",
      "Epoch: [1][1400/2163]\tTime  0.260 ( 0.254)\tData  0.202 ( 0.193)\tLoss 2.2028e+00 (2.3872e+00)\tAcc@1  60.16 ( 57.90)\tAcc@2  75.78 ( 72.04)\n",
      "Epoch: [1][1450/2163]\tTime  0.245 ( 0.254)\tData  0.189 ( 0.193)\tLoss 2.2312e+00 (2.3805e+00)\tAcc@1  65.62 ( 58.02)\tAcc@2  77.34 ( 72.15)\n",
      "Epoch: [1][1500/2163]\tTime  0.255 ( 0.254)\tData  0.190 ( 0.193)\tLoss 2.1233e+00 (2.3736e+00)\tAcc@1  63.28 ( 58.17)\tAcc@2  77.34 ( 72.29)\n",
      "Epoch: [1][1550/2163]\tTime  0.252 ( 0.254)\tData  0.190 ( 0.193)\tLoss 2.1745e+00 (2.3669e+00)\tAcc@1  62.50 ( 58.31)\tAcc@2  68.75 ( 72.38)\n",
      "Epoch: [1][1600/2163]\tTime  0.246 ( 0.254)\tData  0.189 ( 0.193)\tLoss 2.1844e+00 (2.3601e+00)\tAcc@1  64.06 ( 58.43)\tAcc@2  76.56 ( 72.47)\n",
      "Epoch: [1][1650/2163]\tTime  0.267 ( 0.254)\tData  0.210 ( 0.193)\tLoss 2.0552e+00 (2.3533e+00)\tAcc@1  64.84 ( 58.56)\tAcc@2  79.69 ( 72.58)\n",
      "Epoch: [1][1700/2163]\tTime  0.249 ( 0.254)\tData  0.190 ( 0.193)\tLoss 2.2320e+00 (2.3468e+00)\tAcc@1  56.25 ( 58.65)\tAcc@2  72.66 ( 72.67)\n",
      "Epoch: [1][1750/2163]\tTime  0.246 ( 0.254)\tData  0.190 ( 0.193)\tLoss 2.2211e+00 (2.3404e+00)\tAcc@1  63.28 ( 58.77)\tAcc@2  72.66 ( 72.76)\n",
      "Epoch: [1][1800/2163]\tTime  0.255 ( 0.254)\tData  0.193 ( 0.193)\tLoss 2.1223e+00 (2.3345e+00)\tAcc@1  59.38 ( 58.86)\tAcc@2  75.78 ( 72.85)\n",
      "Epoch: [1][1850/2163]\tTime  0.248 ( 0.254)\tData  0.187 ( 0.193)\tLoss 2.0686e+00 (2.3284e+00)\tAcc@1  59.38 ( 58.94)\tAcc@2  76.56 ( 72.93)\n",
      "Epoch: [1][1900/2163]\tTime  0.258 ( 0.254)\tData  0.197 ( 0.193)\tLoss 2.1252e+00 (2.3220e+00)\tAcc@1  58.59 ( 59.05)\tAcc@2  75.00 ( 73.03)\n",
      "Epoch: [1][1950/2163]\tTime  0.252 ( 0.254)\tData  0.193 ( 0.193)\tLoss 2.1039e+00 (2.3160e+00)\tAcc@1  57.03 ( 59.14)\tAcc@2  68.75 ( 73.11)\n",
      "Epoch: [1][2000/2163]\tTime  0.252 ( 0.255)\tData  0.195 ( 0.193)\tLoss 2.0629e+00 (2.3096e+00)\tAcc@1  63.28 ( 59.24)\tAcc@2  75.00 ( 73.19)\n",
      "Epoch: [1][2050/2163]\tTime  0.251 ( 0.255)\tData  0.192 ( 0.193)\tLoss 2.0868e+00 (2.3037e+00)\tAcc@1  62.50 ( 59.31)\tAcc@2  76.56 ( 73.24)\n",
      "Epoch: [1][2100/2163]\tTime  0.259 ( 0.255)\tData  0.189 ( 0.193)\tLoss 2.0556e+00 (2.2975e+00)\tAcc@1  60.94 ( 59.39)\tAcc@2  78.91 ( 73.32)\n",
      "Epoch: [1][2150/2163]\tTime  0.254 ( 0.255)\tData  0.198 ( 0.193)\tLoss 1.9371e+00 (2.2913e+00)\tAcc@1  68.75 ( 59.49)\tAcc@2  80.47 ( 73.42)\n",
      "Test: [  0/541]\tTime  0.211 ( 0.211)\tLoss 1.7197e+00 (1.7197e+00)\tAcc@1  75.00 ( 75.00)\tAcc@5  92.19 ( 92.19)\n",
      "Test: [ 50/541]\tTime  0.216 ( 0.213)\tLoss 2.0164e+00 (1.8386e+00)\tAcc@1  61.72 ( 66.87)\tAcc@5  85.16 ( 88.82)\n",
      "Test: [100/541]\tTime  0.224 ( 0.218)\tLoss 1.8287e+00 (1.8337e+00)\tAcc@1  70.31 ( 67.33)\tAcc@5  92.19 ( 89.09)\n",
      "Test: [150/541]\tTime  0.216 ( 0.219)\tLoss 1.7217e+00 (1.8356e+00)\tAcc@1  68.75 ( 67.43)\tAcc@5  89.06 ( 89.16)\n",
      "Test: [200/541]\tTime  0.219 ( 0.219)\tLoss 1.6970e+00 (1.8348e+00)\tAcc@1  69.53 ( 67.22)\tAcc@5  89.06 ( 89.09)\n",
      "Test: [250/541]\tTime  0.213 ( 0.219)\tLoss 1.8793e+00 (1.8370e+00)\tAcc@1  65.62 ( 67.02)\tAcc@5  86.72 ( 89.08)\n",
      "Test: [300/541]\tTime  0.212 ( 0.218)\tLoss 1.9222e+00 (1.8400e+00)\tAcc@1  64.84 ( 66.85)\tAcc@5  88.28 ( 89.06)\n",
      "Test: [350/541]\tTime  0.215 ( 0.219)\tLoss 1.7405e+00 (1.8398e+00)\tAcc@1  73.44 ( 66.71)\tAcc@5  89.84 ( 89.09)\n",
      "Test: [400/541]\tTime  0.213 ( 0.219)\tLoss 1.7698e+00 (1.8376e+00)\tAcc@1  70.31 ( 66.70)\tAcc@5  92.19 ( 89.15)\n",
      "Test: [450/541]\tTime  0.217 ( 0.219)\tLoss 1.8285e+00 (1.8387e+00)\tAcc@1  67.97 ( 66.61)\tAcc@5  92.19 ( 89.17)\n",
      "Test: [500/541]\tTime  0.212 ( 0.219)\tLoss 1.8788e+00 (1.8389e+00)\tAcc@1  70.31 ( 66.60)\tAcc@5  89.84 ( 89.20)\n",
      " * Acc@1 66.533 Acc@5 89.180\n",
      "Epoch: [2][   0/2163]\tTime  0.267 ( 0.267)\tData  0.202 ( 0.202)\tLoss 2.1522e+00 (2.1522e+00)\tAcc@1  57.81 ( 57.81)\tAcc@2  67.97 ( 67.97)\n",
      "Epoch: [2][  50/2163]\tTime  0.252 ( 0.255)\tData  0.195 ( 0.194)\tLoss 1.9220e+00 (2.0021e+00)\tAcc@1  67.19 ( 64.09)\tAcc@2  81.25 ( 76.78)\n",
      "Epoch: [2][ 100/2163]\tTime  0.246 ( 0.254)\tData  0.187 ( 0.193)\tLoss 2.0234e+00 (1.9965e+00)\tAcc@1  60.94 ( 64.46)\tAcc@2  75.78 ( 77.21)\n",
      "Epoch: [2][ 150/2163]\tTime  0.246 ( 0.253)\tData  0.189 ( 0.192)\tLoss 2.0477e+00 (1.9982e+00)\tAcc@1  61.72 ( 64.30)\tAcc@2  74.22 ( 77.08)\n",
      "Epoch: [2][ 200/2163]\tTime  0.249 ( 0.253)\tData  0.190 ( 0.192)\tLoss 2.0068e+00 (1.9957e+00)\tAcc@1  61.72 ( 64.27)\tAcc@2  76.56 ( 77.07)\n",
      "Epoch: [2][ 250/2163]\tTime  0.256 ( 0.253)\tData  0.198 ( 0.192)\tLoss 2.0432e+00 (1.9925e+00)\tAcc@1  56.25 ( 64.25)\tAcc@2  72.66 ( 77.03)\n",
      "Epoch: [2][ 300/2163]\tTime  0.246 ( 0.254)\tData  0.188 ( 0.192)\tLoss 2.0435e+00 (1.9865e+00)\tAcc@1  58.59 ( 64.33)\tAcc@2  73.44 ( 77.28)\n",
      "Epoch: [2][ 350/2163]\tTime  0.246 ( 0.254)\tData  0.188 ( 0.193)\tLoss 1.7494e+00 (1.9806e+00)\tAcc@1  79.69 ( 64.34)\tAcc@2  86.72 ( 77.37)\n",
      "Epoch: [2][ 400/2163]\tTime  0.246 ( 0.254)\tData  0.189 ( 0.192)\tLoss 1.8814e+00 (1.9755e+00)\tAcc@1  65.62 ( 64.33)\tAcc@2  80.47 ( 77.41)\n",
      "Epoch: [2][ 450/2163]\tTime  0.244 ( 0.253)\tData  0.187 ( 0.192)\tLoss 1.9689e+00 (1.9713e+00)\tAcc@1  63.28 ( 64.29)\tAcc@2  74.22 ( 77.44)\n",
      "Epoch: [2][ 500/2163]\tTime  0.245 ( 0.252)\tData  0.185 ( 0.192)\tLoss 1.8765e+00 (1.9648e+00)\tAcc@1  62.50 ( 64.37)\tAcc@2  78.12 ( 77.52)\n",
      "Epoch: [2][ 550/2163]\tTime  0.244 ( 0.252)\tData  0.187 ( 0.191)\tLoss 1.9509e+00 (1.9591e+00)\tAcc@1  60.16 ( 64.38)\tAcc@2  74.22 ( 77.59)\n",
      "Epoch: [2][ 600/2163]\tTime  0.243 ( 0.251)\tData  0.185 ( 0.191)\tLoss 1.9175e+00 (1.9536e+00)\tAcc@1  60.94 ( 64.44)\tAcc@2  76.56 ( 77.68)\n",
      "Epoch: [2][ 650/2163]\tTime  0.243 ( 0.251)\tData  0.186 ( 0.191)\tLoss 1.9309e+00 (1.9474e+00)\tAcc@1  67.19 ( 64.55)\tAcc@2  78.12 ( 77.75)\n",
      "Epoch: [2][ 700/2163]\tTime  0.249 ( 0.251)\tData  0.188 ( 0.190)\tLoss 1.7456e+00 (1.9430e+00)\tAcc@1  75.00 ( 64.57)\tAcc@2  87.50 ( 77.78)\n",
      "Epoch: [2][ 750/2163]\tTime  0.243 ( 0.250)\tData  0.184 ( 0.190)\tLoss 1.8906e+00 (1.9388e+00)\tAcc@1  64.84 ( 64.60)\tAcc@2  76.56 ( 77.82)\n",
      "Epoch: [2][ 800/2163]\tTime  0.253 ( 0.250)\tData  0.196 ( 0.190)\tLoss 1.8615e+00 (1.9340e+00)\tAcc@1  64.06 ( 64.64)\tAcc@2  78.91 ( 77.82)\n",
      "Epoch: [2][ 850/2163]\tTime  0.241 ( 0.250)\tData  0.184 ( 0.190)\tLoss 1.7540e+00 (1.9291e+00)\tAcc@1  72.66 ( 64.65)\tAcc@2  82.81 ( 77.87)\n",
      "Epoch: [2][ 900/2163]\tTime  0.260 ( 0.250)\tData  0.193 ( 0.190)\tLoss 1.7458e+00 (1.9237e+00)\tAcc@1  68.75 ( 64.71)\tAcc@2  82.03 ( 77.92)\n",
      "Epoch: [2][ 950/2163]\tTime  0.243 ( 0.250)\tData  0.185 ( 0.190)\tLoss 1.7519e+00 (1.9189e+00)\tAcc@1  65.62 ( 64.75)\tAcc@2  78.91 ( 77.95)\n",
      "Epoch: [2][1000/2163]\tTime  0.261 ( 0.250)\tData  0.195 ( 0.190)\tLoss 1.7320e+00 (1.9129e+00)\tAcc@1  73.44 ( 64.80)\tAcc@2  81.25 ( 78.02)\n",
      "Epoch: [2][1050/2163]\tTime  0.243 ( 0.250)\tData  0.185 ( 0.190)\tLoss 1.8149e+00 (1.9083e+00)\tAcc@1  60.16 ( 64.82)\tAcc@2  80.47 ( 78.07)\n",
      "Epoch: [2][1100/2163]\tTime  0.266 ( 0.250)\tData  0.203 ( 0.190)\tLoss 1.7351e+00 (1.9039e+00)\tAcc@1  67.97 ( 64.86)\tAcc@2  79.69 ( 78.06)\n",
      "Epoch: [2][1150/2163]\tTime  0.260 ( 0.251)\tData  0.200 ( 0.191)\tLoss 1.7248e+00 (1.8987e+00)\tAcc@1  65.62 ( 64.91)\tAcc@2  77.34 ( 78.11)\n",
      "Epoch: [2][1200/2163]\tTime  0.255 ( 0.251)\tData  0.196 ( 0.191)\tLoss 1.7718e+00 (1.8931e+00)\tAcc@1  69.53 ( 64.97)\tAcc@2  80.47 ( 78.16)\n",
      "Epoch: [2][1250/2163]\tTime  0.254 ( 0.251)\tData  0.192 ( 0.191)\tLoss 1.8309e+00 (1.8882e+00)\tAcc@1  60.16 ( 64.98)\tAcc@2  75.00 ( 78.19)\n",
      "Epoch: [2][1300/2163]\tTime  0.267 ( 0.251)\tData  0.204 ( 0.191)\tLoss 1.8082e+00 (1.8827e+00)\tAcc@1  63.28 ( 65.06)\tAcc@2  75.78 ( 78.25)\n",
      "Epoch: [2][1350/2163]\tTime  0.243 ( 0.251)\tData  0.184 ( 0.191)\tLoss 1.6825e+00 (1.8768e+00)\tAcc@1  66.41 ( 65.10)\tAcc@2  83.59 ( 78.30)\n",
      "Epoch: [2][1400/2163]\tTime  0.250 ( 0.251)\tData  0.189 ( 0.191)\tLoss 1.9837e+00 (1.8728e+00)\tAcc@1  59.38 ( 65.12)\tAcc@2  71.88 ( 78.31)\n",
      "Epoch: [2][1450/2163]\tTime  0.257 ( 0.252)\tData  0.192 ( 0.191)\tLoss 1.7153e+00 (1.8675e+00)\tAcc@1  67.97 ( 65.18)\tAcc@2  75.78 ( 78.35)\n",
      "Epoch: [2][1500/2163]\tTime  0.250 ( 0.252)\tData  0.192 ( 0.191)\tLoss 1.6903e+00 (1.8625e+00)\tAcc@1  70.31 ( 65.22)\tAcc@2  85.16 ( 78.41)\n",
      "Epoch: [2][1550/2163]\tTime  0.250 ( 0.252)\tData  0.190 ( 0.191)\tLoss 1.8530e+00 (1.8584e+00)\tAcc@1  58.59 ( 65.22)\tAcc@2  71.88 ( 78.43)\n",
      "Epoch: [2][1600/2163]\tTime  0.290 ( 0.252)\tData  0.209 ( 0.191)\tLoss 1.7652e+00 (1.8536e+00)\tAcc@1  52.34 ( 65.22)\tAcc@2  74.22 ( 78.44)\n",
      "Epoch: [2][1650/2163]\tTime  0.256 ( 0.252)\tData  0.201 ( 0.191)\tLoss 1.6597e+00 (1.8490e+00)\tAcc@1  68.75 ( 65.24)\tAcc@2  80.47 ( 78.46)\n",
      "Epoch: [2][1700/2163]\tTime  0.253 ( 0.252)\tData  0.187 ( 0.191)\tLoss 1.6960e+00 (1.8439e+00)\tAcc@1  65.62 ( 65.28)\tAcc@2  81.25 ( 78.53)\n",
      "Epoch: [2][1750/2163]\tTime  0.261 ( 0.252)\tData  0.199 ( 0.191)\tLoss 1.7181e+00 (1.8398e+00)\tAcc@1  67.19 ( 65.28)\tAcc@2  80.47 ( 78.56)\n",
      "Epoch: [2][1800/2163]\tTime  0.252 ( 0.252)\tData  0.186 ( 0.192)\tLoss 1.6338e+00 (1.8351e+00)\tAcc@1  66.41 ( 65.31)\tAcc@2  82.03 ( 78.58)\n",
      "Epoch: [2][1850/2163]\tTime  0.260 ( 0.252)\tData  0.197 ( 0.192)\tLoss 1.6180e+00 (1.8305e+00)\tAcc@1  68.75 ( 65.34)\tAcc@2  80.47 ( 78.62)\n",
      "Epoch: [2][1900/2163]\tTime  0.247 ( 0.252)\tData  0.186 ( 0.192)\tLoss 1.5869e+00 (1.8253e+00)\tAcc@1  69.53 ( 65.40)\tAcc@2  83.59 ( 78.67)\n",
      "Epoch: [2][1950/2163]\tTime  0.254 ( 0.253)\tData  0.195 ( 0.192)\tLoss 1.8020e+00 (1.8209e+00)\tAcc@1  60.16 ( 65.44)\tAcc@2  73.44 ( 78.70)\n",
      "Epoch: [2][2000/2163]\tTime  0.252 ( 0.253)\tData  0.193 ( 0.192)\tLoss 1.5695e+00 (1.8157e+00)\tAcc@1  66.41 ( 65.51)\tAcc@2  83.59 ( 78.76)\n",
      "Epoch: [2][2050/2163]\tTime  0.271 ( 0.253)\tData  0.188 ( 0.192)\tLoss 1.6643e+00 (1.8112e+00)\tAcc@1  63.28 ( 65.53)\tAcc@2  78.12 ( 78.79)\n",
      "Epoch: [2][2100/2163]\tTime  0.249 ( 0.253)\tData  0.190 ( 0.192)\tLoss 1.5020e+00 (1.8063e+00)\tAcc@1  67.19 ( 65.59)\tAcc@2  84.38 ( 78.85)\n",
      "Epoch: [2][2150/2163]\tTime  0.269 ( 0.253)\tData  0.206 ( 0.192)\tLoss 1.5256e+00 (1.8018e+00)\tAcc@1  69.53 ( 65.63)\tAcc@2  84.38 ( 78.89)\n",
      "Test: [  0/541]\tTime  0.214 ( 0.214)\tLoss 1.3005e+00 (1.3005e+00)\tAcc@1  75.78 ( 75.78)\tAcc@5  95.31 ( 95.31)\n",
      "Test: [ 50/541]\tTime  0.211 ( 0.217)\tLoss 1.6536e+00 (1.4341e+00)\tAcc@1  62.50 ( 69.82)\tAcc@5  87.50 ( 91.18)\n",
      "Test: [100/541]\tTime  0.210 ( 0.217)\tLoss 1.3681e+00 (1.4269e+00)\tAcc@1  71.09 ( 70.16)\tAcc@5  93.75 ( 91.37)\n",
      "Test: [150/541]\tTime  0.220 ( 0.217)\tLoss 1.3276e+00 (1.4291e+00)\tAcc@1  71.09 ( 70.26)\tAcc@5  91.41 ( 91.36)\n",
      "Test: [200/541]\tTime  0.214 ( 0.217)\tLoss 1.2957e+00 (1.4306e+00)\tAcc@1  72.66 ( 69.97)\tAcc@5  91.41 ( 91.33)\n",
      "Test: [250/541]\tTime  0.208 ( 0.217)\tLoss 1.5026e+00 (1.4335e+00)\tAcc@1  68.75 ( 69.79)\tAcc@5  89.06 ( 91.33)\n",
      "Test: [300/541]\tTime  0.212 ( 0.217)\tLoss 1.5160e+00 (1.4360e+00)\tAcc@1  64.84 ( 69.69)\tAcc@5  90.62 ( 91.31)\n",
      "Test: [350/541]\tTime  0.208 ( 0.217)\tLoss 1.3475e+00 (1.4358e+00)\tAcc@1  75.00 ( 69.63)\tAcc@5  90.62 ( 91.38)\n",
      "Test: [400/541]\tTime  0.208 ( 0.216)\tLoss 1.3723e+00 (1.4340e+00)\tAcc@1  76.56 ( 69.68)\tAcc@5  93.75 ( 91.43)\n",
      "Test: [450/541]\tTime  0.209 ( 0.215)\tLoss 1.4132e+00 (1.4352e+00)\tAcc@1  73.44 ( 69.63)\tAcc@5  94.53 ( 91.44)\n",
      "Test: [500/541]\tTime  0.211 ( 0.215)\tLoss 1.4481e+00 (1.4354e+00)\tAcc@1  71.09 ( 69.63)\tAcc@5  92.19 ( 91.45)\n",
      " * Acc@1 69.588 Acc@5 91.441\n",
      "Epoch: [3][   0/2163]\tTime  0.262 ( 0.262)\tData  0.194 ( 0.194)\tLoss 1.5858e+00 (1.5858e+00)\tAcc@1  64.84 ( 64.84)\tAcc@2  77.34 ( 77.34)\n",
      "Epoch: [3][  50/2163]\tTime  0.242 ( 0.246)\tData  0.186 ( 0.187)\tLoss 1.6080e+00 (1.5991e+00)\tAcc@1  65.62 ( 67.54)\tAcc@2  77.34 ( 80.36)\n",
      "Epoch: [3][ 100/2163]\tTime  0.244 ( 0.245)\tData  0.185 ( 0.187)\tLoss 1.6899e+00 (1.5917e+00)\tAcc@1  61.72 ( 67.54)\tAcc@2  79.69 ( 80.60)\n",
      "Epoch: [3][ 150/2163]\tTime  0.246 ( 0.245)\tData  0.186 ( 0.187)\tLoss 1.5840e+00 (1.5908e+00)\tAcc@1  72.66 ( 67.23)\tAcc@2  78.91 ( 80.43)\n",
      "Epoch: [3][ 200/2163]\tTime  0.245 ( 0.245)\tData  0.187 ( 0.187)\tLoss 1.5856e+00 (1.5854e+00)\tAcc@1  67.97 ( 67.29)\tAcc@2  82.81 ( 80.53)\n",
      "Epoch: [3][ 250/2163]\tTime  0.244 ( 0.245)\tData  0.185 ( 0.187)\tLoss 1.5646e+00 (1.5795e+00)\tAcc@1  64.06 ( 67.50)\tAcc@2  80.47 ( 80.65)\n",
      "Epoch: [3][ 300/2163]\tTime  0.243 ( 0.245)\tData  0.185 ( 0.187)\tLoss 1.5078e+00 (1.5729e+00)\tAcc@1  67.97 ( 67.59)\tAcc@2  83.59 ( 80.85)\n",
      "Epoch: [3][ 350/2163]\tTime  0.246 ( 0.245)\tData  0.184 ( 0.187)\tLoss 1.5897e+00 (1.5709e+00)\tAcc@1  64.06 ( 67.66)\tAcc@2  82.81 ( 80.93)\n",
      "Epoch: [3][ 400/2163]\tTime  0.243 ( 0.245)\tData  0.186 ( 0.187)\tLoss 1.6888e+00 (1.5657e+00)\tAcc@1  58.59 ( 67.72)\tAcc@2  71.09 ( 80.98)\n",
      "Epoch: [3][ 450/2163]\tTime  0.252 ( 0.245)\tData  0.186 ( 0.187)\tLoss 1.6264e+00 (1.5617e+00)\tAcc@1  57.03 ( 67.71)\tAcc@2  78.12 ( 81.01)\n",
      "Epoch: [3][ 500/2163]\tTime  0.243 ( 0.245)\tData  0.187 ( 0.187)\tLoss 1.5127e+00 (1.5584e+00)\tAcc@1  65.62 ( 67.70)\tAcc@2  79.69 ( 80.99)\n",
      "Epoch: [3][ 550/2163]\tTime  0.243 ( 0.245)\tData  0.186 ( 0.187)\tLoss 1.5990e+00 (1.5549e+00)\tAcc@1  67.19 ( 67.77)\tAcc@2  78.91 ( 81.00)\n",
      "Epoch: [3][ 600/2163]\tTime  0.246 ( 0.245)\tData  0.187 ( 0.187)\tLoss 1.5263e+00 (1.5512e+00)\tAcc@1  69.53 ( 67.80)\tAcc@2  82.03 ( 81.05)\n",
      "Epoch: [3][ 650/2163]\tTime  0.250 ( 0.246)\tData  0.191 ( 0.187)\tLoss 1.4768e+00 (1.5475e+00)\tAcc@1  68.75 ( 67.79)\tAcc@2  79.69 ( 81.07)\n",
      "Epoch: [3][ 700/2163]\tTime  0.240 ( 0.246)\tData  0.183 ( 0.187)\tLoss 1.4620e+00 (1.5438e+00)\tAcc@1  67.19 ( 67.86)\tAcc@2  82.81 ( 81.13)\n",
      "Epoch: [3][ 750/2163]\tTime  0.241 ( 0.246)\tData  0.184 ( 0.187)\tLoss 1.4527e+00 (1.5406e+00)\tAcc@1  67.97 ( 67.86)\tAcc@2  83.59 ( 81.11)\n",
      "Epoch: [3][ 800/2163]\tTime  0.247 ( 0.246)\tData  0.190 ( 0.187)\tLoss 1.4060e+00 (1.5367e+00)\tAcc@1  70.31 ( 67.94)\tAcc@2  84.38 ( 81.17)\n",
      "Epoch: [3][ 850/2163]\tTime  0.243 ( 0.246)\tData  0.185 ( 0.187)\tLoss 1.4107e+00 (1.5334e+00)\tAcc@1  68.75 ( 67.96)\tAcc@2  79.69 ( 81.17)\n",
      "Epoch: [3][ 900/2163]\tTime  0.247 ( 0.245)\tData  0.189 ( 0.187)\tLoss 1.5342e+00 (1.5296e+00)\tAcc@1  64.06 ( 67.97)\tAcc@2  75.00 ( 81.18)\n",
      "Epoch: [3][ 950/2163]\tTime  0.240 ( 0.245)\tData  0.184 ( 0.187)\tLoss 1.4185e+00 (1.5249e+00)\tAcc@1  74.22 ( 68.01)\tAcc@2  82.81 ( 81.23)\n",
      "Epoch: [3][1000/2163]\tTime  0.248 ( 0.246)\tData  0.190 ( 0.187)\tLoss 1.4436e+00 (1.5206e+00)\tAcc@1  71.88 ( 68.06)\tAcc@2  82.03 ( 81.28)\n",
      "Epoch: [3][1050/2163]\tTime  0.243 ( 0.246)\tData  0.186 ( 0.187)\tLoss 1.3229e+00 (1.5180e+00)\tAcc@1  73.44 ( 68.06)\tAcc@2  85.16 ( 81.28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "dataset = EuroCropsDataset(root=root,partition=partition,country=country)\n",
    "           \n",
    "fold_len = int(len(dataset) / 5)\n",
    "n_train = len(dataset) -  fold_len\n",
    "train_set, val_set =random_split(dataset,(n_train, fold_len),generator=torch.Generator().manual_seed(42))  \n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "pse_tae = PSE_TAE(device).to(device)\n",
    "\n",
    "focal_loss = FocalLoss(gamma).to(device)\n",
    "\n",
    "# Adam Optimizer\n",
    "optimizer = torch.optim.Adam(pse_tae.parameters(), lr=learning_rate, betas=(b1, b2), weight_decay=weight_decay)\n",
    "\n",
    "# stops training when validation loss no longer decreases by min_delta after X epochs as defined by patience.\n",
    "early_stopper = EarlyStopper(patience=5, min_delta=0.2)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "pse_tae, optimizer, start_epoch = load_checkpoint(pse_tae, optimizer)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "\n",
    "    # ----------\n",
    "    #  Training\n",
    "    # ----------\n",
    "\n",
    "    train(train_loader,\n",
    "            pse_tae,\n",
    "            focal_loss,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            print_freq,\n",
    "            device)\n",
    "\n",
    "    # -----------\n",
    "    #  Validation\n",
    "    # -----------\n",
    "\n",
    "    acc1, val_loss = validate(val_loader,\n",
    "                    pse_tae,\n",
    "                    focal_loss,\n",
    "                    epoch,\n",
    "                    print_freq,\n",
    "                    device)\n",
    "\n",
    "    # -----------\n",
    "    #  Remember best acc@1 and save checkpoint\n",
    "    # -----------\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "    \n",
    "    if early_stopper.early_stop(val_loss):             \n",
    "        break\n",
    "\n",
    "    save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': pse_tae.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eurocrops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
